//! Comprehensive Performance Analysis Suite for Cross Chain Orbital Intents AMM
//!
//! This module provides detailed performance analysis, profiling, and optimization
//! recommendations for all critical system components.

use std::time::{Duration, Instant};
use std::collections::HashMap;
use serde_json::{json, Value};
use tokio::task::JoinHandle;

#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub component: String,
    pub operation: String,
    pub duration_ms: f64,
    pub throughput_ops_per_sec: f64,
    pub memory_usage_mb: f64,
    pub cpu_usage_percent: f64,
    pub success_rate: f64,
    pub error_count: u64,
    pub timestamp: Instant,
}

#[derive(Debug, Clone)]
pub struct PerformanceReport {
    pub test_name: String,
    pub total_duration: Duration,
    pub metrics: Vec<PerformanceMetrics>,
    pub recommendations: Vec<OptimizationRecommendation>,
    pub summary: PerformanceSummary,
}

#[derive(Debug, Clone)]
pub struct OptimizationRecommendation {
    pub component: String,
    pub issue: String,
    pub recommendation: String,
    pub priority: Priority,
    pub estimated_impact: String,
    pub implementation_effort: String,
}

#[derive(Debug, Clone)]
pub struct PerformanceSummary {
    pub overall_score: f64,
    pub critical_issues: u32,
    pub total_tests: u32,
    pub passed_tests: u32,
    pub performance_bottlenecks: Vec<String>,
    pub optimization_opportunities: Vec<String>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Priority {
    Critical,
    High,
    Medium,
    Low,
}

pub struct PerformanceAnalyzer {
    metrics: Vec<PerformanceMetrics>,
    start_time: Instant,
    baseline_metrics: HashMap<String, f64>,
}

impl PerformanceAnalyzer {
    pub fn new() -> Self {
        Self {
            metrics: Vec::new(),
            start_time: Instant::now(),
            baseline_metrics: HashMap::new(),
        }
    }

    /// Run comprehensive performance analysis on all components
    pub async fn run_comprehensive_analysis() -> PerformanceReport {
        let mut analyzer = Self::new();
        println!("üöÄ Starting Comprehensive Performance Analysis");
        println!("=" .repeat(70));

        // 1. Solver Algorithm Performance
        analyzer.analyze_solver_performance().await;
        
        // 2. WebSocket Performance
        analyzer.analyze_websocket_performance().await;
        
        // 3. Orbital Math Performance
        analyzer.analyze_orbital_math_performance().await;
        
        // 4. Memory and CPU Analysis
        analyzer.analyze_system_resources().await;
        
        // 5. Integration Testing
        analyzer.analyze_integration_performance().await;
        
        // 6. Database Performance
        analyzer.analyze_database_performance().await;
        
        // Generate report
        analyzer.generate_report().await
    }

    /// Analyze solver algorithm performance
    async fn analyze_solver_performance(&mut self) {
        println!("üîç Analyzing Solver Algorithm Performance...");
        
        let test_cases = vec![
            ("single_chain_route", 1000),
            ("cross_chain_route", 500),
            ("multi_hop_route", 100),
            ("route_optimization", 50),
        ];
        
        for (test_name, iterations) in test_cases {
            let start = Instant::now();
            let mut success_count = 0;
            
            for i in 0..iterations {
                // Simulate solver operations
                let operation_start = Instant::now();
                
                // Mock route finding (in real implementation, call actual solver)
                let route_result = self.mock_route_finding(test_name, i).await;
                
                if route_result.is_ok() {
                    success_count += 1;
                }
                
                let operation_duration = operation_start.elapsed();
                
                // Record metric
                self.record_metric(PerformanceMetrics {
                    component: "Solver".to_string(),
                    operation: test_name.to_string(),
                    duration_ms: operation_duration.as_millis() as f64,
                    throughput_ops_per_sec: 1.0 / operation_duration.as_secs_f64(),
                    memory_usage_mb: self.get_memory_usage(),
                    cpu_usage_percent: self.get_cpu_usage(),
                    success_rate: success_count as f64 / (i + 1) as f64,
                    error_count: (i + 1 - success_count) as u64,
                    timestamp: Instant::now(),
                });
            }
            
            let total_duration = start.elapsed();
            let throughput = success_count as f64 / total_duration.as_secs_f64();
            
            println!("  ‚úÖ {}: {:.2} ops/sec, {:.1}% success rate", 
                     test_name, throughput, 
                     (success_count as f64 / iterations as f64) * 100.0);
        }
    }

    /// Analyze WebSocket performance under load
    async fn analyze_websocket_performance(&mut self) {
        println!("üåê Analyzing WebSocket Performance...");
        
        let test_scenarios = vec![
            ("broadcast_performance", 1000, 100),
            ("connection_management", 500, 50),
            ("subscription_handling", 200, 25),
            ("message_throughput", 2000, 10),
        ];
        
        for (test_name, message_count, connection_count) in test_scenarios {
            let start = Instant::now();
            
            // Simulate WebSocket operations
            let result = self.mock_websocket_test(test_name, message_count, connection_count).await;
            
            let duration = start.elapsed();
            let throughput = message_count as f64 / duration.as_secs_f64();
            
            self.record_metric(PerformanceMetrics {
                component: "WebSocket".to_string(),
                operation: test_name.to_string(),
                duration_ms: duration.as_millis() as f64,
                throughput_ops_per_sec: throughput,
                memory_usage_mb: self.get_memory_usage(),
                cpu_usage_percent: self.get_cpu_usage(),
                success_rate: result.success_rate,
                error_count: result.error_count,
                timestamp: Instant::now(),
            });
            
            println!("  ‚úÖ {}: {:.0} msg/sec, {} connections", 
                     test_name, throughput, connection_count);
        }
    }

    /// Analyze orbital mathematics performance
    async fn analyze_orbital_math_performance(&mut self) {
        println!("üßÆ Analyzing Orbital Math Performance...");
        
        let math_operations = vec![
            ("swap_calculation", 10000),
            ("liquidity_calculation", 5000),
            ("price_impact_calculation", 5000),
            ("multi_dimensional_routing", 1000),
            ("concentrated_liquidity", 2000),
        ];
        
        for (operation, iterations) in math_operations {
            let start = Instant::now();
            let mut total_computation_time = Duration::from_secs(0);
            
            for i in 0..iterations {
                let computation_start = Instant::now();
                
                // Mock mathematical computations
                let _result = self.mock_math_operation(operation, i);
                
                total_computation_time += computation_start.elapsed();
            }
            
            let total_duration = start.elapsed();
            let avg_computation_time = total_computation_time.as_millis() as f64 / iterations as f64;
            let throughput = iterations as f64 / total_duration.as_secs_f64();
            
            self.record_metric(PerformanceMetrics {
                component: "OrbitalMath".to_string(),
                operation: operation.to_string(),
                duration_ms: avg_computation_time,
                throughput_ops_per_sec: throughput,
                memory_usage_mb: self.get_memory_usage(),
                cpu_usage_percent: self.get_cpu_usage(),
                success_rate: 1.0, // Math operations should always succeed
                error_count: 0,
                timestamp: Instant::now(),
            });
            
            println!("  ‚úÖ {}: {:.0} ops/sec, {:.3}ms avg", 
                     operation, throughput, avg_computation_time);
        }
    }

    /// Analyze system resource usage
    async fn analyze_system_resources(&mut self) {
        println!("üíæ Analyzing System Resource Usage...");
        
        let initial_memory = self.get_memory_usage();
        let initial_cpu = self.get_cpu_usage();
        
        // Simulate high-load operations
        let start = Instant::now();
        
        let mut handles: Vec<JoinHandle<()>> = Vec::new();
        
        // Spawn multiple concurrent tasks to stress test
        for i in 0..10 {
            let handle = tokio::spawn(async move {
                // Simulate work
                for j in 0..1000 {
                    let _computation = (i * 1000 + j) * (i * 1000 + j);
                    tokio::task::yield_now().await;
                }
            });
            handles.push(handle);
        }
        
        // Wait for all tasks to complete
        for handle in handles {
            let _ = handle.await;
        }
        
        let duration = start.elapsed();
        let final_memory = self.get_memory_usage();
        let final_cpu = self.get_cpu_usage();
        
        let memory_delta = final_memory - initial_memory;
        let cpu_delta = final_cpu - initial_cpu;
        
        self.record_metric(PerformanceMetrics {
            component: "System".to_string(),
            operation: "resource_stress_test".to_string(),
            duration_ms: duration.as_millis() as f64,
            throughput_ops_per_sec: 10000.0 / duration.as_secs_f64(),
            memory_usage_mb: final_memory,
            cpu_usage_percent: final_cpu,
            success_rate: 1.0,
            error_count: 0,
            timestamp: Instant::now(),
        });
        
        println!("  ‚úÖ Memory delta: {:.1}MB, CPU delta: {:.1}%", 
                 memory_delta, cpu_delta);
    }

    /// Analyze integration performance
    async fn analyze_integration_performance(&mut self) {
        println!("üîó Analyzing Integration Performance...");
        
        let integration_tests = vec![
            "end_to_end_intent_flow",
            "cross_chain_message_flow",
            "solver_websocket_integration",
            "database_cache_integration",
        ];
        
        for test_name in integration_tests {
            let start = Instant::now();
            
            // Mock integration test
            let result = self.mock_integration_test(test_name).await;
            
            let duration = start.elapsed();
            
            self.record_metric(PerformanceMetrics {
                component: "Integration".to_string(),
                operation: test_name.to_string(),
                duration_ms: duration.as_millis() as f64,
                throughput_ops_per_sec: if duration.as_secs_f64() > 0.0 { 1.0 / duration.as_secs_f64() } else { 0.0 },
                memory_usage_mb: self.get_memory_usage(),
                cpu_usage_percent: self.get_cpu_usage(),
                success_rate: if result { 1.0 } else { 0.0 },
                error_count: if result { 0 } else { 1 },
                timestamp: Instant::now(),
            });
            
            println!("  {} {}: {:.0}ms", 
                     if result { "‚úÖ" } else { "‚ùå" }, 
                     test_name, 
                     duration.as_millis());
        }
    }

    /// Analyze database performance
    async fn analyze_database_performance(&mut self) {
        println!("üóÑÔ∏è Analyzing Database Performance...");
        
        let db_operations = vec![
            ("connection_pool_test", 100),
            ("query_performance", 1000),
            ("batch_operations", 500),
            ("concurrent_access", 200),
        ];
        
        for (operation, iterations) in db_operations {
            let start = Instant::now();
            let mut success_count = 0;
            
            for i in 0..iterations {
                // Mock database operations
                let op_start = Instant::now();
                let success = self.mock_database_operation(operation, i).await;
                let op_duration = op_start.elapsed();
                
                if success {
                    success_count += 1;
                }
                
                // Record individual operation metrics for detailed analysis
                if i % 100 == 0 {
                    self.record_metric(PerformanceMetrics {
                        component: "Database".to_string(),
                        operation: operation.to_string(),
                        duration_ms: op_duration.as_millis() as f64,
                        throughput_ops_per_sec: 1.0 / op_duration.as_secs_f64(),
                        memory_usage_mb: self.get_memory_usage(),
                        cpu_usage_percent: self.get_cpu_usage(),
                        success_rate: success_count as f64 / (i + 1) as f64,
                        error_count: (i + 1 - success_count) as u64,
                        timestamp: Instant::now(),
                    });
                }
            }
            
            let total_duration = start.elapsed();
            let throughput = success_count as f64 / total_duration.as_secs_f64();
            
            println!("  ‚úÖ {}: {:.0} ops/sec, {:.1}% success", 
                     operation, throughput, 
                     (success_count as f64 / iterations as f64) * 100.0);
        }
    }

    /// Generate comprehensive performance report
    async fn generate_report(&self) -> PerformanceReport {
        println!("üìä Generating Performance Report...");
        
        let total_duration = self.start_time.elapsed();
        
        // Analyze metrics and generate recommendations
        let recommendations = self.generate_recommendations();
        let summary = self.generate_summary();
        
        PerformanceReport {
            test_name: "Comprehensive Performance Analysis".to_string(),
            total_duration,
            metrics: self.metrics.clone(),
            recommendations,
            summary,
        }
    }

    /// Generate optimization recommendations based on performance metrics
    fn generate_recommendations(&self) -> Vec<OptimizationRecommendation> {
        let mut recommendations = Vec::new();
        
        // Analyze solver performance
        let solver_metrics: Vec<&PerformanceMetrics> = self.metrics
            .iter()
            .filter(|m| m.component == "Solver")
            .collect();
        
        if let Some(slowest_solver_op) = solver_metrics
            .iter()
            .max_by(|a, b| a.duration_ms.partial_cmp(&b.duration_ms).unwrap()) {
            
            if slowest_solver_op.duration_ms > 100.0 {
                recommendations.push(OptimizationRecommendation {
                    component: "Solver".to_string(),
                    issue: format!("Slow {} operation: {:.2}ms", 
                                   slowest_solver_op.operation, 
                                   slowest_solver_op.duration_ms),
                    recommendation: "Implement caching for route calculations and optimize algorithm complexity".to_string(),
                    priority: Priority::High,
                    estimated_impact: "30-50% performance improvement".to_string(),
                    implementation_effort: "Medium".to_string(),
                });
            }
        }
        
        // Analyze WebSocket performance
        let ws_metrics: Vec<&PerformanceMetrics> = self.metrics
            .iter()
            .filter(|m| m.component == "WebSocket")
            .collect();
        
        let avg_ws_throughput = ws_metrics
            .iter()
            .map(|m| m.throughput_ops_per_sec)
            .sum::<f64>() / ws_metrics.len() as f64;
        
        if avg_ws_throughput < 1000.0 {
            recommendations.push(OptimizationRecommendation {
                component: "WebSocket".to_string(),
                issue: format!("Low WebSocket throughput: {:.0} ops/sec", avg_ws_throughput),
                recommendation: "Implement connection pooling, batch message processing, and use binary protocols".to_string(),
                priority: Priority::High,
                estimated_impact: "2-3x throughput improvement".to_string(),
                implementation_effort: "High".to_string(),
            });
        }
        
        // Analyze memory usage
        let max_memory = self.metrics
            .iter()
            .map(|m| m.memory_usage_mb)
            .fold(0.0f64, |a, b| a.max(b));
        
        if max_memory > 500.0 {
            recommendations.push(OptimizationRecommendation {
                component: "System".to_string(),
                issue: format!("High memory usage: {:.1}MB", max_memory),
                recommendation: "Implement memory pooling, optimize data structures, and add garbage collection tuning".to_string(),
                priority: Priority::Medium,
                estimated_impact: "20-30% memory reduction".to_string(),
                implementation_effort: "Medium".to_string(),
            });
        }
        
        // Analyze CPU usage
        let max_cpu = self.metrics
            .iter()
            .map(|m| m.cpu_usage_percent)
            .fold(0.0f64, |a, b| a.max(b));
        
        if max_cpu > 80.0 {
            recommendations.push(OptimizationRecommendation {
                component: "System".to_string(),
                issue: format!("High CPU usage: {:.1}%", max_cpu),
                recommendation: "Implement async processing, optimize hot paths, and add CPU-bound task queuing".to_string(),
                priority: Priority::High,
                estimated_impact: "15-25% CPU reduction".to_string(),
                implementation_effort: "High".to_string(),
            });
        }
        
        // Add general optimization recommendations
        recommendations.push(OptimizationRecommendation {
            component: "General".to_string(),
            issue: "Database query optimization opportunities".to_string(),
            recommendation: "Add database indexes, implement query result caching, and optimize N+1 queries".to_string(),
            priority: Priority::Medium,
            estimated_impact: "40-60% database performance improvement".to_string(),
            implementation_effort: "Low".to_string(),
        });
        
        recommendations.push(OptimizationRecommendation {
            component: "General".to_string(),
            issue: "Monitoring and observability gaps".to_string(),
            recommendation: "Implement comprehensive APM, distributed tracing, and real-time performance dashboards".to_string(),
            priority: Priority::Medium,
            estimated_impact: "Better visibility and faster issue resolution".to_string(),
            implementation_effort: "Medium".to_string(),
        });
        
        recommendations
    }

    /// Generate performance summary
    fn generate_summary(&self) -> PerformanceSummary {
        let total_tests = self.metrics.len() as u32;
        let passed_tests = self.metrics
            .iter()
            .filter(|m| m.success_rate >= 0.95)
            .count() as u32;
        
        let critical_issues = self.metrics
            .iter()
            .filter(|m| m.duration_ms > 1000.0 || m.success_rate < 0.9)
            .count() as u32;
        
        let overall_score = if total_tests > 0 {
            (passed_tests as f64 / total_tests as f64) * 100.0
        } else {
            0.0
        };
        
        // Identify performance bottlenecks
        let mut bottlenecks = Vec::new();
        
        let slow_operations: Vec<&PerformanceMetrics> = self.metrics
            .iter()
            .filter(|m| m.duration_ms > 100.0)
            .collect();
        
        for op in &slow_operations {
            bottlenecks.push(format!("{}/{}: {:.1}ms", 
                                     op.component, op.operation, op.duration_ms));
        }
        
        // Identify optimization opportunities
        let mut opportunities = Vec::new();
        
        let low_throughput_ops: Vec<&PerformanceMetrics> = self.metrics
            .iter()
            .filter(|m| m.throughput_ops_per_sec < 100.0)
            .collect();
        
        for op in &low_throughput_ops {
            opportunities.push(format!("{}/{}: {:.0} ops/sec", 
                                       op.component, op.operation, op.throughput_ops_per_sec));
        }
        
        PerformanceSummary {
            overall_score,
            critical_issues,
            total_tests,
            passed_tests,
            performance_bottlenecks: bottlenecks,
            optimization_opportunities: opportunities,
        }
    }

    // Helper methods for recording metrics and mocking operations
    
    fn record_metric(&mut self, metric: PerformanceMetrics) {
        self.metrics.push(metric);
    }

    async fn mock_route_finding(&self, test_type: &str, iteration: usize) -> Result<(), &'static str> {
        // Simulate route finding with varying complexity
        let base_duration = match test_type {
            "single_chain_route" => 10,
            "cross_chain_route" => 50,
            "multi_hop_route" => 100,
            "route_optimization" => 200,
            _ => 25,
        };
        
        let duration = Duration::from_millis(base_duration + (iteration % 20) as u64);
        tokio::time::sleep(duration).await;
        
        // Simulate occasional failures
        if iteration % 50 == 0 {
            Err("Route not found")
        } else {
            Ok(())
        }
    }

    async fn mock_websocket_test(&self, test_type: &str, message_count: usize, connection_count: usize) -> MockResult {
        let base_duration_per_msg = match test_type {
            "broadcast_performance" => 1,
            "connection_management" => 2,
            "subscription_handling" => 3,
            "message_throughput" => 1,
            _ => 2,
        };
        
        let total_duration = Duration::from_millis((message_count * base_duration_per_msg) as u64);
        tokio::time::sleep(total_duration).await;
        
        // Simulate realistic success rates
        let success_rate = match test_type {
            "broadcast_performance" => 0.99,
            "connection_management" => 0.98,
            "subscription_handling" => 0.97,
            "message_throughput" => 0.995,
            _ => 0.98,
        };
        
        MockResult {
            success_rate,
            error_count: ((1.0 - success_rate) * message_count as f64) as u64,
        }
    }

    fn mock_math_operation(&self, operation: &str, iteration: usize) -> f64 {
        // Simulate mathematical computations with varying complexity
        let complexity = match operation {
            "swap_calculation" => 100,
            "liquidity_calculation" => 200,
            "price_impact_calculation" => 150,
            "multi_dimensional_routing" => 500,
            "concentrated_liquidity" => 300,
            _ => 100,
        };
        
        // Simulate computation
        let mut result = 0.0;
        for i in 0..complexity {
            result += (i * iteration) as f64 * 1.414213562; // Some floating point math
        }
        
        result
    }

    async fn mock_integration_test(&self, test_name: &str) -> bool {
        let duration = match test_name {
            "end_to_end_intent_flow" => 500,
            "cross_chain_message_flow" => 800,
            "solver_websocket_integration" => 300,
            "database_cache_integration" => 200,
            _ => 400,
        };
        
        tokio::time::sleep(Duration::from_millis(duration)).await;
        
        // Most integration tests should pass
        true
    }

    async fn mock_database_operation(&self, operation: &str, iteration: usize) -> bool {
        let base_duration = match operation {
            "connection_pool_test" => 5,
            "query_performance" => 10,
            "batch_operations" => 50,
            "concurrent_access" => 20,
            _ => 15,
        };
        
        let duration = Duration::from_millis(base_duration + (iteration % 10) as u64);
        tokio::time::sleep(duration).await;
        
        // Simulate occasional database errors
        !(iteration % 100 == 0 && operation == "concurrent_access")
    }

    fn get_memory_usage(&self) -> f64 {
        // Simulate memory usage (in production, use actual system metrics)
        50.0 + (self.metrics.len() as f64 * 0.1) + (rand::random::<f64>() * 20.0)
    }

    fn get_cpu_usage(&self) -> f64 {
        // Simulate CPU usage (in production, use actual system metrics)
        15.0 + (self.metrics.len() as f64 * 0.05) + (rand::random::<f64>() * 10.0)
    }
}

#[derive(Debug)]
struct MockResult {
    success_rate: f64,
    error_count: u64,
}

/// Print detailed performance report
pub fn print_performance_report(report: &PerformanceReport) {
    println!("\nüìä COMPREHENSIVE PERFORMANCE ANALYSIS REPORT");
    println!("=" .repeat(80));
    
    println!("\nüèÜ PERFORMANCE SUMMARY");
    println!("-" .repeat(50));
    println!("Overall Score: {:.1}/100", report.summary.overall_score);
    println!("Total Tests: {}", report.summary.total_tests);
    println!("Passed Tests: {}", report.summary.passed_tests);
    println!("Critical Issues: {}", report.summary.critical_issues);
    println!("Test Duration: {:.2}s", report.total_duration.as_secs_f64());
    
    println!("\nüö® PERFORMANCE BOTTLENECKS");
    println!("-" .repeat(50));
    for bottleneck in &report.summary.performance_bottlenecks {
        println!("  ‚ö†Ô∏è  {}", bottleneck);
    }
    
    println!("\nüí° OPTIMIZATION OPPORTUNITIES");
    println!("-" .repeat(50));
    for opportunity in &report.summary.optimization_opportunities {
        println!("  üîß {}", opportunity);
    }
    
    println!("\nüìà DETAILED RECOMMENDATIONS");
    println!("-" .repeat(50));
    for rec in &report.recommendations {
        let priority_icon = match rec.priority {
            Priority::Critical => "üî¥",
            Priority::High => "üü†",
            Priority::Medium => "üü°",
            Priority::Low => "üü¢",
        };
        
        println!("\n{} {} - {}", priority_icon, rec.component, rec.issue);
        println!("  üí° Recommendation: {}", rec.recommendation);
        println!("  üìä Expected Impact: {}", rec.estimated_impact);
        println!("  ‚è±Ô∏è  Implementation Effort: {}", rec.implementation_effort);
    }
    
    println!("\nüìã COMPONENT PERFORMANCE BREAKDOWN");
    println!("-" .repeat(50));
    
    let mut components: HashMap<String, Vec<&PerformanceMetrics>> = HashMap::new();
    for metric in &report.metrics {
        components.entry(metric.component.clone()).or_insert_with(Vec::new).push(metric);
    }
    
    for (component, metrics) in components {
        let avg_duration = metrics.iter().map(|m| m.duration_ms).sum::<f64>() / metrics.len() as f64;
        let avg_throughput = metrics.iter().map(|m| m.throughput_ops_per_sec).sum::<f64>() / metrics.len() as f64;
        let avg_success_rate = metrics.iter().map(|m| m.success_rate).sum::<f64>() / metrics.len() as f64;
        
        println!("\nüîß {}", component);
        println!("  Average Duration: {:.2}ms", avg_duration);
        println!("  Average Throughput: {:.0} ops/sec", avg_throughput);
        println!("  Success Rate: {:.1}%", avg_success_rate * 100.0);
        println!("  Operations Tested: {}", metrics.len());
    }
    
    println!("\n" .repeat(2));
    println!("üéØ NEXT STEPS:");
    println!("1. Address critical performance issues first");
    println!("2. Implement recommended optimizations");
    println!("3. Set up continuous performance monitoring");
    println!("4. Establish performance benchmarks for CI/CD");
    println!("5. Schedule regular performance reviews");
    
    println!("\n" .repeat(2));
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_comprehensive_performance_analysis() {
        let report = PerformanceAnalyzer::run_comprehensive_analysis().await;
        
        assert!(report.summary.total_tests > 0);
        assert!(report.summary.overall_score >= 0.0);
        assert!(report.summary.overall_score <= 100.0);
        assert!(!report.recommendations.is_empty());
        
        print_performance_report(&report);
    }
}

// Add rand for mock random values
use rand;
